# GitHub Copilot Instructions for Kaggle Competitions

## Project Context

This is an AI/ML project workspace optimized for Kaggle competitions. The environment includes all major ML libraries and follows best practices for competitive data science.

## Environment Setup

- Python 3.12.11 in virtual environment (.venv)
- All major ML libraries: scikit-learn, xgboost, lightgbm, catboost, tensorflow, pytorch
- Data manipulation: pandas, numpy, polars
- Visualization: matplotlib, seaborn, plotly
- Computer vision: opencv-python, pillow, albumentations
- NLP: transformers, datasets

## Code Style & Standards

### General Guidelines

- Use type hints for all function parameters and returns
- Write docstrings for all functions and classes
- Prefer f-strings for string formatting
- Use meaningful variable names (no single letters except for loops)
- Add comments explaining complex algorithms or domain-specific logic
- Dont use emoji in code or comments

### Kaggle-Specific Best Practices

- Always set random seeds for reproducibility using `set_seed(42)` from src.utils
- Use cross-validation for model evaluation (prefer StratifiedKFold for classification)
- Implement proper train/validation/test splits
- Log important metrics and hyperparameters using `get_logger()` from src.utils
- Optimize memory usage with `reduce_memory_usage()` for large datasets
- Save model checkpoints and predictions
- Use ensemble methods when appropriate

## Data Science Patterns

### Data Loading & Exploration

```python
# Preferred data loading pattern
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from src.utils import set_seed, get_logger, reduce_memory_usage

# Initialize utilities
set_seed(42)
logger = get_logger(__name__)

def load_and_explore_data(file_path: str) -> pd.DataFrame:
    """Load data and perform initial exploration."""
    logger.info(f"Loading data from {file_path}")
    df = pd.read_csv(file_path)
    logger.info(f"Shape: {df.shape}")

    # Optimize memory usage
    df = reduce_memory_usage(df, verbose=True)

    return df
```

### Feature Engineering

- Create meaningful feature names with prefixes (e.g., 'fe*', 'agg*', 'enc\_')
- Use sklearn pipelines for preprocessing
- Implement target encoding with proper cross-validation
- Handle missing values explicitly
- Create interaction features when relevant

### Model Training

- Use sklearn's Pipeline for preprocessing + model
- Implement early stopping for gradient boosting models
- Log training progress with wandb or mlflow
- Save feature importance plots
- Use optuna for hyperparameter optimization

### Model Validation

- Always use cross-validation (minimum 5 folds)
- Calculate confidence intervals for CV scores
- Check for overfitting by comparing train/validation curves
- Validate on holdout test set only once

## Built-in Utility Functions

This project includes pre-built utility functions in `src.utils` to streamline common Kaggle tasks:

### Reproducibility

```python
from src.utils import set_seed

# Always call at the start of notebooks/scripts
set_seed(42)  # Sets seeds for random, numpy, torch (if available)
```

### Logging

```python
from src.utils import get_logger

# Create logger for tracking progress
logger = get_logger(__name__)
logger.info("Starting model training...")
logger.warning("Low CV score detected")
```

### Memory Optimization

```python
from src.utils import reduce_memory_usage

# Reduce DataFrame memory usage (essential for large datasets)
df = reduce_memory_usage(df, verbose=True)
# Automatically converts int64->int8/16/32 and float64->float32 when possible
```

### Standard Import Pattern

```python
# Always use this import pattern at the start of files
from src.utils import set_seed, get_logger, reduce_memory_usage

# Initialize
set_seed(42)
logger = get_logger(__name__)
```

## Library-Specific Guidelines

### XGBoost/LightGBM/CatBoost

- Use early stopping with eval_set
- Monitor both training and validation metrics
- Set appropriate categorical feature handling
- Use GPU acceleration when available
- Save and load models using native formats (.pkl, .json)

### PyTorch/TensorFlow

- Use DataLoader for batch processing
- Implement proper train/eval modes
- Use learning rate scheduling
- Save model state_dict, not full model
- Implement gradient clipping for RNNs

### Computer Vision

- Use albumentations for data augmentation
- Implement proper train/val transforms
- Use timm models for transfer learning
- Handle image normalization consistently
- Use TTA (Test Time Augmentation) for inference

### NLP

- Use Hugging Face transformers tokenizers
- Implement proper padding and attention masks
- Use gradient accumulation for large models
- Save tokenizer with model
- Implement text cleaning pipelines

## File Organization

```
project/
├── data/
│   ├── raw/          # Original competition data
│   ├── processed/    # Cleaned and feature-engineered data
│   └── external/     # Additional datasets
├── models/           # Saved model files
├── notebooks/        # Jupyter notebooks for exploration
├── src/
│   ├── data/         # Data loading and preprocessing
│   ├── features/     # Feature engineering
│   ├── models/       # Model definitions and training
│   └── utils/        # Utility functions
├── submissions/      # Competition submission files
└── configs/          # Configuration files
```

## Common Kaggle Techniques

### Feature Engineering

- Target encoding with smoothing
- Frequency encoding for categorical variables
- Polynomial features for numerical variables
- Time-based features (day, month, hour, etc.)
- Aggregation features (mean, std, min, max by groups)

### Model Stacking

- Use out-of-fold predictions for level-1 models
- Implement proper CV for stacking
- Use diverse base models (tree-based + linear + neural)
- Apply rank averaging for final ensemble

### Time Series

- Use proper time-based splits (no data leakage)
- Create lag features with appropriate windows
- Handle seasonality and trends
- Use rolling statistics

## Performance Optimization

- Use pandas.category for categorical variables
- Implement memory optimization techniques
- Use parallel processing where appropriate
- Profile code with line_profiler or cProfile
- Cache expensive computations

## Debugging & Monitoring

- Add assertions for data shape and type validation
- Log intermediate results during pipeline execution
- Use tqdm for progress bars in long operations
- Implement data quality checks
- Monitor memory usage during training

## Competition Submission

- Always validate submission format
- Use descriptive filenames with timestamps
- Keep track of CV scores vs. public LB scores
- Document model configurations and hyperparameters
- Maintain submission log with performance metrics

Remember: Focus on creating robust, reproducible solutions that generalize well to unseen data. Avoid overfitting to the public leaderboard!
